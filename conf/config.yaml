labels: [first, not_first]

do_train: True
do_evalate: False

pretrained_path: /home/sugimoto/BERT-base_mecab-ipadic-bpe-32k_whole-word-mask
save_path: ~

train_params:
  train_file_path: /home/sugimoto/experiments/inputs/train.tsv
  test_file_path: /home/sugimoto/experiments/inputs/test.tsv
  max_seq_length: 128
  batch_size: 16
  num_epochs: 1
  lr: 5e-5